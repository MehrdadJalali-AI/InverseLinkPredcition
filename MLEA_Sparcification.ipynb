{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MehrdadJalali-AI/InverseLinkPredcition/blob/main/MLEA_Sparcification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e85d2092-cfca-4f65-8043-5302322104fc",
      "metadata": {
        "id": "e85d2092-cfca-4f65-8043-5302322104fc",
        "outputId": "374c976c-a79d-45b4-cf25-bfa40a14efef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best modularity score: 0.8340 after 300 evaluations\n",
            "Sparsified graph saved to 'mlea_sparsified_graph_refined.csv'\n",
            "Remaining nodes: 12561, edges: 103583\n",
            "Total runtime: 4160.06 seconds\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import networkx as nx\n",
        "from rdkit import Chem\n",
        "from rdkit.Chem import AllChem\n",
        "import networkx.algorithms.community as nx_comm\n",
        "import time\n",
        "from typing import Callable, Tuple\n",
        "import warnings\n",
        "\n",
        "# Suppress RDKit warnings\n",
        "from rdkit import rdBase\n",
        "rdBase.DisableLog(\"rdApp.*\")\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "class LotusEffectAlgorithm:\n",
        "    \"\"\"A population-based optimization algorithm for graph sparsification.\"\"\"\n",
        "    def __init__(self, population_size: int, dimensions: int, lower_bound: float,\n",
        "                 upper_bound: float, max_evals: int, fitness_function: Callable):\n",
        "        self.pop_size = population_size\n",
        "        self.dims = dimensions\n",
        "        self.lb = lower_bound\n",
        "        self.ub = upper_bound\n",
        "        self.max_evals = max_evals\n",
        "        self.fitness_func = fitness_function\n",
        "        self.population = np.random.uniform(lower_bound, upper_bound, (population_size, dimensions))\n",
        "        self.best_solution = self.population[0].copy()\n",
        "        self.best_fitness = float('inf')\n",
        "        self.evals = 0\n",
        "\n",
        "    def mutate(self, individual: np.ndarray, mutation_rate: float = 0.1) -> np.ndarray:\n",
        "        \"\"\"Apply random mutation to an individual.\"\"\"\n",
        "        mask = np.random.random(self.dims) < mutation_rate\n",
        "        individual[mask] = np.random.uniform(self.lb, self.ub, mask.sum())\n",
        "        return np.clip(individual, self.lb, self.ub)\n",
        "\n",
        "    def optimize(self) -> Tuple[np.ndarray, float, int]:\n",
        "        \"\"\"Optimize the edge mask to minimize fitness (maximize modularity).\"\"\"\n",
        "        for _ in range(self.max_evals // self.pop_size):\n",
        "            for i in range(self.pop_size):\n",
        "                if self.evals >= self.max_evals:\n",
        "                    break\n",
        "\n",
        "                # Evaluate fitness\n",
        "                fitness = self.fitness_func(self.population[i])\n",
        "                self.evals += 1\n",
        "\n",
        "                if fitness < self.best_fitness:\n",
        "                    self.best_fitness = fitness\n",
        "                    self.best_solution = self.population[i].copy()\n",
        "\n",
        "                # Mutate to explore solution space\n",
        "                self.population[i] = self.mutate(self.population[i])\n",
        "\n",
        "        return self.best_solution, self.best_fitness, self.evals\n",
        "\n",
        "def load_edges_list(filename: str) -> pd.DataFrame:\n",
        "    \"\"\"Load edge list from a CSV file.\"\"\"\n",
        "    return pd.read_csv(filename)\n",
        "\n",
        "def generate_fingerprint(smiles: str) -> np.ndarray:\n",
        "    \"\"\"Generate a Morgan fingerprint from a SMILES string.\"\"\"\n",
        "    mol = Chem.MolFromSmiles(smiles)\n",
        "    if mol is None:\n",
        "        return np.zeros(1024, dtype=np.float32)\n",
        "    return np.array(AllChem.GetMorganFingerprintAsBitVect(mol, 2, nBits=1024), dtype=np.float32)\n",
        "\n",
        "def label_encode_metal_names(metal_names: np.ndarray) -> np.ndarray:\n",
        "    \"\"\"Convert metal names to integer labels.\"\"\"\n",
        "    unique_metals = np.unique(metal_names)\n",
        "    metal_dict = {metal: idx for idx, metal in enumerate(unique_metals)}\n",
        "    return np.array([metal_dict[metal] for metal in metal_names], dtype=np.int32)\n",
        "\n",
        "def load_summary_data(filename: str, node_labels: np.ndarray) -> pd.DataFrame:\n",
        "    \"\"\"Load and process summary data for nodes.\"\"\"\n",
        "    summary_data = pd.read_csv(filename, index_col=0)\n",
        "    linker_smiles = summary_data['linker SMILES']\n",
        "    linker_features = np.stack(linker_smiles.apply(generate_fingerprint).values)\n",
        "    metal_features = label_encode_metal_names(summary_data['metal']).reshape(-1, 1)\n",
        "    other_features = summary_data[['Largest Cavity Diameter', 'Pore Limiting Diameter',\n",
        "                                  'Largest Free Sphere']].astype(np.float32).values\n",
        "    features = np.concatenate((linker_features, metal_features, other_features), axis=1)\n",
        "    return pd.DataFrame(features, index=summary_data.index)\n",
        "\n",
        "def graph_modularity_score(edge_mask: np.ndarray, edge_list: list, original_graph: nx.Graph) -> float:\n",
        "    \"\"\"Calculate the negative modularity score of a sparsified graph.\"\"\"\n",
        "    graph = nx.Graph(original_graph)  # Copy the original graph\n",
        "    for i, keep in enumerate(edge_mask):\n",
        "        if keep < 0.5 and graph.has_edge(*edge_list[i]):\n",
        "            graph.remove_edge(*edge_list[i])\n",
        "\n",
        "    if graph.number_of_edges() == 0:\n",
        "        return 1.0  # Worst case: no edges\n",
        "    try:\n",
        "        communities = nx_comm.greedy_modularity_communities(graph)\n",
        "        return -nx_comm.modularity(graph, communities)\n",
        "    except Exception:\n",
        "        return 1.0  # Handle edge cases gracefully\n",
        "\n",
        "def main():\n",
        "    \"\"\"Main function to sparsify a graph using the Lotus Effect Algorithm.\"\"\"\n",
        "    start_time = time.time()\n",
        "    config = {\n",
        "        'edges_list_filename': 'edges_list_0.8_Full_2.csv',\n",
        "        'summary_data_filename': '1M1L3D_summary.csv',\n",
        "        'output_file': 'mlea_sparsified_graph_refined.csv',\n",
        "        'population_size': 20,\n",
        "        'max_function_evaluations': 300\n",
        "    }\n",
        "\n",
        "    # Load data\n",
        "    edges = load_edges_list(config['edges_list_filename'])\n",
        "    node_labels = pd.concat([edges['source'], edges['target']]).unique()\n",
        "    summary_data = load_summary_data(config['summary_data_filename'], node_labels)\n",
        "\n",
        "    # Build initial graph\n",
        "    G = nx.Graph()\n",
        "    edge_list = []\n",
        "    for _, row in edges.iterrows():\n",
        "        G.add_edge(row['source'], row['target'], weight=row['weight'])\n",
        "        edge_list.append((row['source'], row['target']))\n",
        "\n",
        "    # Define fitness function and optimize\n",
        "    fitness_func = lambda mask: graph_modularity_score(mask, edge_list, G)\n",
        "    lea = LotusEffectAlgorithm(\n",
        "        population_size=config['population_size'],\n",
        "        dimensions=len(edge_list),\n",
        "        lower_bound=0.0,\n",
        "        upper_bound=1.0,\n",
        "        max_evals=config['max_function_evaluations'],\n",
        "        fitness_function=fitness_func\n",
        "    )\n",
        "    best_mask, best_score, evals = lea.optimize()\n",
        "\n",
        "    # Apply best mask to sparsify graph\n",
        "    G_final = nx.Graph(G)\n",
        "    for i, keep in enumerate(best_mask):\n",
        "        if keep < 0.5 and G_final.has_edge(*edge_list[i]):\n",
        "            G_final.remove_edge(*edge_list[i])\n",
        "\n",
        "    # Save and report results\n",
        "    nx.write_edgelist(G_final, config['output_file'], data=['weight'])\n",
        "    print(f\"Best modularity score: {-best_score:.4f} after {evals} evaluations\")\n",
        "    print(f\"Sparsified graph saved to '{config['output_file']}'\")\n",
        "    print(f\"Remaining nodes: {G_final.number_of_nodes()}, edges: {G_final.number_of_edges()}\")\n",
        "    print(f\"Total runtime: {time.time() - start_time:.2f} seconds\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ef770c24-bcf4-498f-bd65-981bf73e80c6",
      "metadata": {
        "id": "ef770c24-bcf4-498f-bd65-981bf73e80c6"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0rc1"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}